{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiIPTNXeTkLhDuL2MUNtXb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aansheeagrwal/python-training/blob/main/GEN_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generative AI:-\n",
        "Generative AI encompasses algorithms that can produce new content across various media,such as text, images, music and more.This groundbreaking technology is transforming multiple multiple industries by facilitating innovative creativity and enhancing automation processes.\n",
        "\n",
        "## Definition:-\n",
        "Generative AI is a subset of artificial intelligence.\n",
        "\n",
        "##Applications of GenAI:-\n",
        "It can be used in diverse fiels such as art, music,writting,and gaming.\n",
        "\n",
        "##Technology behind it:-\n",
        "it often utilizes techniques such as neural networks and deep learning to generate outputs that mimic human-human like creativity.\n",
        "\n",
        "##Traditional AI VS GEN AI:-\n",
        "###Traditional AI:-\n",
        "Analyzes data for tasks like classification and prediction,relying on relying on pre-existing datasets.\n",
        "##GenAI:-\n",
        "Focusing on creating new content,generating unique outputs beyond its training data.\n",
        "##Use Cases:-\n",
        "Traditional AI in recommendation systems; GenAI for image,text,and music.\n",
        "\n",
        "##GenAI,VS Machine learning, Deep learning, NLP :-\n",
        "##Machine Learning:-\n",
        "A broader field tht encompasses algorithms that learn from data, which may or may not involve GenAI tasks.\n",
        "##Deep Learning:-\n",
        "A subset of ML that uses neural networks with many layers. GenAI often employs deep learning models to produce high-quality outputs.\n",
        "##Natural Language Processing:-\n",
        "A field focussed on the interaction between computers and human language, where GenAI can create human-like text responses.\n",
        "##Real Use Cases of Genai:-\n",
        "\n",
        "\n",
        "1.   Content Creation:- Tools like ChatGpt and DALL-E.\n",
        "2.   Gaming:- It is used to create game environment and character dialogues enhancing player experience.\n",
        "3.   HealthCare:- It can assist in drug discovery by generating molecular structures on data.\n",
        "\n",
        "GPT AI Models:- It is used for text generation.\n",
        "\n",
        "DALL-E Models:- It is used for image generation.\n",
        "\n",
        "StyleGAN:-it is used for high quality image generation.\n",
        "\n",
        "##Ethical challenges:-\n",
        "\n",
        "\n",
        "*   Bias and Fairness:- GenAI can perpetuate biases present in traning data,data,leading to unfair outputs.\n",
        "*   Misinformation:- The ability to create hyper-reaistic content raises concerns about fake news.\n",
        "*   Intellectual Property:- Question about ownership arise regarding AI-generated content.\n",
        "\n",
        "##Auto encoder:-\n",
        "Autoencoder are neural network that aim to learn a crompressed low dimensional representation of the input data they consist of an encoder and the decoder.\n",
        "The encoder map the input data to the latent space and decoder reconstruct the input from this latent reprsentation.\n",
        "\n",
        "##Variational Auto Encoder:-\n",
        "Variational autoencoder extend autoencoders by encoding the input data in the probability distribution in the latent space. The latent space is a lower dimensional reprentation of the input data learned by autoencoder.\n",
        "\n",
        "Mean + Variance = Probability Distribution\n",
        "\n",
        "##Steps for autoencoder:-\n",
        "* Input text(TF-IDF)\n",
        "* Encoder(Dense layer -> vector)\n",
        "* Decoder(vector -> Dense Layer)\n",
        "* Reconstructed(TF-IDF)\n",
        "\n",
        "##Steps for varitaional Autoencoder:-\n",
        "\n",
        "\n",
        "1.   Input-Text(TF-IDF)\n",
        "2.   Encoder\n",
        "3.   Reparametrization Trick\n",
        "4.   Decoder(vector -> dense layer) -> sample new z from N(0,1)-> New Words\n",
        "5.   Top Terms not euqal to original text.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sQ_PLwBPX2Ko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "msJsBH4HUKJU"
      },
      "outputs": [],
      "source": [
        "##Autoencoder--\n",
        "text = [\"Artificial Intelligence is Transforming the world.\", \"Deep learning model require large datasets.\",\"Natural Language Processing enables chatbots.\",\"Computer vision hep in image recognition.\",\"Generative models create realistic content\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TF-IDF vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf = TfidfVectorizer()\n",
        "tf1 = tf.fit_transform(text).toarray()\n",
        "vocab = tf.get_feature_names_out()\n",
        "in_dim = tf1.shape\n",
        "in_dim=tf1.shape[1]"
      ],
      "metadata": {
        "id": "f_s7_TC7vjsG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojJjVp-PxIDF",
        "outputId": "a5d67db6-f696-4ede-98cd-e1a04c7a3e25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.40824829 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.40824829 0.40824829 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.40824829 0.40824829 0.         0.40824829]\n",
            " [0.         0.         0.         0.         0.         0.40824829\n",
            "  0.40824829 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.40824829 0.40824829 0.40824829\n",
            "  0.         0.         0.         0.         0.         0.40824829\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.4472136  0.         0.         0.         0.\n",
            "  0.         0.4472136  0.         0.         0.         0.\n",
            "  0.         0.         0.4472136  0.         0.         0.\n",
            "  0.         0.4472136  0.4472136  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.40824829 0.         0.         0.\n",
            "  0.         0.         0.         0.40824829 0.40824829 0.40824829\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.40824829 0.\n",
            "  0.         0.         0.40824829 0.        ]\n",
            " [0.         0.         0.         0.4472136  0.4472136  0.\n",
            "  0.         0.         0.4472136  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.4472136  0.         0.         0.4472136  0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9jwcSSHx8kP",
        "outputId": "f1825fcb-3fcf-4e47-a209-61450e54eefe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['artificial', 'chatbots', 'computer', 'content', 'create',\n",
              "       'datasets', 'deep', 'enables', 'generative', 'hep', 'image', 'in',\n",
              "       'intelligence', 'is', 'language', 'large', 'learning', 'model',\n",
              "       'models', 'natural', 'processing', 'realistic', 'recognition',\n",
              "       'require', 'the', 'transforming', 'vision', 'world'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSZJ-eUJx-bP",
        "outputId": "04c77233-a47e-4ce3-83c3-e54fd3d81fdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,Dense\n",
        "\n",
        "en_dim = 5\n",
        "input_layer = Input(shape=(in_dim,))\n",
        "encoded_layer = Dense(en_dim,activation=\"relu\")(input_layer)\n",
        "decode_layer = Dense(in_dim,activation=\"sigmoid\")(encoded_layer)\n",
        "\n",
        "autoencodermodel = Model(input_layer,decode_layer)\n",
        "autoencodermodel.compile(optimizer='adam', loss='mse')\n",
        "autoencodermodel.fit(tf1,tf1,epochs=1,verbose=0)\n",
        "auto_output = autoencodermodel.predict(tf1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW2TYatiz18T",
        "outputId": "94354e27-f995-4218-f942-d2d34ec6051d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oZvDCfmb3XYo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}